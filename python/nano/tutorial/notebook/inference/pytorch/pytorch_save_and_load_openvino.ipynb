{"cells":[{"cell_type":"markdown","metadata":{},"source":["  [View the runnable example on GitHub](https://github.com/intel-analytics/BigDL/tree/main/python/nano/tutorial/notebook/inference/pytorch/pytorch_save_and_load_openvino.ipynb)"]},{"cell_type":"markdown","metadata":{},"source":["  # Save and load openvino model\n","  This example illustrates how to save and load a model accelerated by openvino.\n","  In this example, we use a ResNet18 model pretrained. Then, by calling `trace(model, accelerator=\"onnxruntime\"...)`, we can obtain a model accelarated by onnxruntime method provided by BigDL-Nano for inference. By calling `save(model_name, path)` , we could save the model to a folder. By calling `load(path)`, we could load the model from a folder."]},{"cell_type":"markdown","metadata":{},"source":["  To inference using Bigdl-nano InferenceOptimizer, the following packages need to be installed first. We recommend you to use [Miniconda](https://docs.conda.io/en/latest/miniconda.html) to prepare the environment and install the following packages in a conda environment.\n","\n","  You can create a conda environment by executing:\n","\n","  ```\n","  # \"nano\" is conda environment name, you can use any name you like.\n","  conda create -n nano python=3.7 setuptools=58.0.4\n","  conda activate nano\n","  ```\n","\n","  > 📝 **Note**: \n","  >\n","  > during your installation, there may be some warnings or errors about version, just ignore them.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Necessary packages for inference accelaration\n","!pip install --pre --upgrade bigdl-nano[pytorch]\n","!pip install openvino-dev\n"]},{"cell_type":"markdown","metadata":{},"source":["  First, prepare model. We use a pretrained ResNet18 model(`model_ft` in following code) in this example."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/cpx/anaconda3/envs/junwang-resnext-oob/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","/home/cpx/anaconda3/envs/junwang-resnext-oob/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/home/cpx/anaconda3/envs/junwang-resnext-oob/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from torchvision.models import resnet18\n","\n","model_ft = resnet18(pretrained=True)\n","model_ft.eval()\n"]},{"cell_type":"markdown","metadata":{},"source":["  Accelerated Inference Using OpenVINO"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model Optimizer arguments:\n","Common parameters:\n","\t- Path to the Input Model: \t/tmp/tmpu3s0dy8p/tmp.onnx\n","\t- Path for generated IR: \t/tmp/tmp5h1d_svs\n","\t- IR output name: \ttmp\n","\t- Log level: \tERROR\n","\t- Batch: \tNot specified, inherited from the model\n","\t- Input layers: \tNot specified, inherited from the model\n","\t- Output layers: \tNot specified, inherited from the model\n","\t- Input shapes: \tNot specified, inherited from the model\n","\t- Source layout: \tNot specified\n","\t- Target layout: \tNot specified\n","\t- Layout: \tNot specified\n","\t- Mean values: \tNot specified\n","\t- Scale values: \tNot specified\n","\t- Scale factor: \tNot specified\n","\t- Precision of IR: \tFP32\n","\t- Enable fusing: \tTrue\n","\t- User transformations: \tNot specified\n","\t- Reverse input channels: \tFalse\n","\t- Enable IR generation for fixed input shape: \tFalse\n","\t- Use the transformations config file: \tNone\n","Advanced parameters:\n","\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n","\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n","OpenVINO runtime found in: \t/home/cpx/anaconda3/envs/junwang-resnext-oob/lib/python3.7/site-packages/openvino\n","OpenVINO runtime version: \t2022.2.0-7713-af16ea1d79a-releases/2022/2\n","Model Optimizer version: \t2022.2.0-7713-af16ea1d79a-releases/2022/2\n","[ SUCCESS ] Generated IR version 11 model.\n","[ SUCCESS ] XML file: /tmp/tmp5h1d_svs/tmp.xml\n","[ SUCCESS ] BIN file: /tmp/tmp5h1d_svs/tmp.bin\n","[ SUCCESS ] Total execution time: 0.52 seconds. \n","[ SUCCESS ] Memory consumed: 164 MB. \n","[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n","Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n","tensor([111, 111])\n"]}],"source":["from bigdl.nano.pytorch import InferenceOptimizer\n","ov_model = InferenceOptimizer.trace(model_ft,\n","                                        accelerator=\"openvino\",\n","                                        input_sample=torch.rand(1, 3, 224, 224))\n","\n","x = torch.rand(2, 3, 224, 224)\n","y_hat = ov_model(x)\n","predictions = y_hat.argmax(dim=1)\n","print(predictions)\n"]},{"cell_type":"markdown","metadata":{},"source":["  Save Optimized Model\n","  The saved model files will be saved at \"./optimized_model_ov\" directory\n"," There are 3 files in optimized_model_ov, users only need to take \".bin\" and \".xml\" file for further usage:\n","*   nano_model_meta.yml: meta information of the saved model checkpoint\n","*   ov_saved_model.bin: contains the weights and biases binary data of model\n","*   ov_saved_model.xml: model checkpoint for general use, describes model structure"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["InferenceOptimizer.save(ov_model, \"./optimized_model_ov\")"]},{"cell_type":"markdown","metadata":{},"source":["  Load the Optimized Model"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["loaded_model = InferenceOptimizer.load(\"./optimized_model_ov\")"]},{"cell_type":"markdown","metadata":{},"source":["  Inference with the Loaded Model"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([111, 111])\n"]}],"source":["y_hat = loaded_model(x)\n","predictions = y_hat.argmax(dim=1)\n","print(predictions)"]},{"cell_type":"markdown","metadata":{},"source":["  > 📚 **Related Readings**\n","  >\n","  > - [How to install BigDL-Nano](https://bigdl.readthedocs.io/en/latest/doc/Nano/Overview/nano.html#install)\n","  > - [How to install BigDL-Nano in Google Colab](https://bigdl.readthedocs.io/en/latest/doc/Nano/Howto/install_in_colab.html)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.13 ('junwang-resnext-oob')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"2c2c667a59d63f4d9cf9e9a8f7eff73ad81424da777ad3c4a3346b0ce2b012b2"}}},"nbformat":4,"nbformat_minor":2}
