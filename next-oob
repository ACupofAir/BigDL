[1mdiff --git a/python/chronos/src/bigdl/chronos/forecaster/base_forecaster.py b/python/chronos/src/bigdl/chronos/forecaster/base_forecaster.py[m
[1mindex 15a350301..8838dd812 100644[m
[1m--- a/python/chronos/src/bigdl/chronos/forecaster/base_forecaster.py[m
[1m+++ b/python/chronos/src/bigdl/chronos/forecaster/base_forecaster.py[m
[36m@@ -213,8 +213,8 @@[m [mclass BasePytorchForecaster(Forecaster):[m
         if self.tune_trainer.hposearcher.objective.mo_hpo:[m
             return self.internal[m
         # else:[m
[31m-            # reset train and validation datasets[m
[31m-            # self.tune_trainer.reset_train_val_dataloaders(self.internal)[m
[32m+[m[32m        # reset train and validation datasets[m
[32m+[m[32m        # self.tune_trainer.reset_train_val_dataloaders(self.internal)[m
 [m
     def search_summary(self):[m
         """[m
[36m@@ -371,6 +371,15 @@[m [mclass BasePytorchForecaster(Forecaster):[m
             if isinstance(data, DataLoader) and self.num_processes:[m
                 data = dataloader_batch_resize(data, batch_size, self.num_processes)[m
 [m
[32m+[m[32m            # Before multi-process training, check the data's batchsize to avoid[m
[32m+[m[32m            # the small batchsize inference result[m
[32m+[m[32m            if data.batch_size < 5 and self.has_bn:[m
[32m+[m[32m                warnings.warn([m
[32m+[m[32m                    f"The sample number {data.batch_size} of per process is too small for "[m
[32m+[m[32m                    "multi-process training and can lead to large inaccuracy. It is recommended to "[m
[32m+[m[32m                    "reduce num_process or set the forecaster's num_process=1 to use single process "[m
[32m+[m[32m                    "training.")[m
[32m+[m
             # training process[m
             # forecaster_log_dir is a temp directory for training log[m
             # validation_ckpt_dir is a temp directory for best checkpoint on validation data[m
[1mdiff --git a/python/chronos/src/bigdl/chronos/forecaster/lstm_forecaster.py b/python/chronos/src/bigdl/chronos/forecaster/lstm_forecaster.py[m
[1mindex 48c9258e1..6d638e34c 100644[m
[1m--- a/python/chronos/src/bigdl/chronos/forecaster/lstm_forecaster.py[m
[1m+++ b/python/chronos/src/bigdl/chronos/forecaster/lstm_forecaster.py[m
[36m@@ -146,6 +146,7 @@[m [mclass LSTMForecaster(BasePytorchForecaster):[m
         self.lr = lr[m
         self.metrics = metrics[m
         self.seed = seed[m
[32m+[m[32m        self.has_bn = False[m
 [m
         # nano setting[m
         current_num_threads = torch.get_num_threads()[m
[1mdiff --git a/python/chronos/src/bigdl/chronos/forecaster/nbeats_forecaster.py b/python/chronos/src/bigdl/chronos/forecaster/nbeats_forecaster.py[m
[1mindex cb5c8016d..73689adc1 100644[m
[1m--- a/python/chronos/src/bigdl/chronos/forecaster/nbeats_forecaster.py[m
[1m+++ b/python/chronos/src/bigdl/chronos/forecaster/nbeats_forecaster.py[m
[36m@@ -154,6 +154,7 @@[m [mclass NBeatsForecaster(BasePytorchForecaster):[m
         self.lr = lr[m
         self.seed = seed[m
         self.metrics = metrics[m
[32m+[m[32m        self.has_bn = False[m
 [m
         # nano settings[m
         current_num_threads = torch.get_num_threads()[m
[1mdiff --git a/python/chronos/src/bigdl/chronos/forecaster/seq2seq_forecaster.py b/python/chronos/src/bigdl/chronos/forecaster/seq2seq_forecaster.py[m
[1mindex 6ce2578d1..44cc6d505 100644[m
[1m--- a/python/chronos/src/bigdl/chronos/forecaster/seq2seq_forecaster.py[m
[1m+++ b/python/chronos/src/bigdl/chronos/forecaster/seq2seq_forecaster.py[m
[36m@@ -150,6 +150,7 @@[m [mclass Seq2SeqForecaster(BasePytorchForecaster):[m
         self.lr = lr[m
         self.metrics = metrics[m
         self.seed = seed[m
[32m+[m[32m        self.has_bn = False[m
 [m
         # nano setting[m
         current_num_threads = torch.get_num_threads()[m
[1mdiff --git a/python/chronos/src/bigdl/chronos/forecaster/tcn_forecaster.py b/python/chronos/src/bigdl/chronos/forecaster/tcn_forecaster.py[m
[1mindex 4c6455da3..3a7db5c51 100644[m
[1m--- a/python/chronos/src/bigdl/chronos/forecaster/tcn_forecaster.py[m
[1m+++ b/python/chronos/src/bigdl/chronos/forecaster/tcn_forecaster.py[m
[36m@@ -170,6 +170,7 @@[m [mclass TCNForecaster(BasePytorchForecaster):[m
         self.lr = lr[m
         self.metrics = metrics[m
         self.seed = seed[m
[32m+[m[32m        self.has_bn = not self.dummy_encoder[m
 [m
         # nano setting[m
         current_num_threads = torch.get_num_threads()[m
